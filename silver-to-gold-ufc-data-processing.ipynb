{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed3acd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:26.696690Z",
     "iopub.status.busy": "2025-09-30T22:27:26.696296Z",
     "iopub.status.idle": "2025-09-30T22:32:09.206372Z",
     "shell.execute_reply": "2025-09-30T22:32:09.205347Z"
    },
    "papermill": {
     "duration": 282.520526,
     "end_time": "2025-09-30T22:32:09.210334",
     "exception": false,
     "start_time": "2025-09-30T22:27:26.689808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1156878345.py:743: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  long_df = long_df.groupby('fighter', group_keys=False).apply(calculate_outcomes)\n",
      "/tmp/ipykernel_13/1156878345.py:744: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  long_df = long_df.groupby('fighter', group_keys=False).apply(calculate_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written ufc_model_full_analysis_rounds.csv — 8217 records | 279.85s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "UFC model processing pipeline for Kaggle.\n",
    "\n",
    "This script provides a high‑performance reimplementation of the UFC fight\n",
    "statistics pipeline tailored for Kaggle.  It reads a Silver++ dataset\n",
    "from a local CSV, computes a variety of engineered features and\n",
    "rolling statistics, and writes the results back to a CSV.  The\n",
    "pipeline avoids expensive pandas ``rolling()`` calls by using NumPy\n",
    "cumulative sums and vectorised operations throughout.  All rolling\n",
    "windows exclude the current fight (equivalent to a ``shift(1)`` in\n",
    "pandas) to prevent data leakage into future predictions.\n",
    "\n",
    "Input:\n",
    "    /kaggle/input/ufc-fight-forecast-complete-gold-modeling-dataset/UFC_full_data_silver.csv\n",
    "\n",
    "Output:\n",
    "    ufc_model_full_analysis_rounds.csv in the working directory\n",
    "\n",
    "The high level steps are:\n",
    "\n",
    "1. Read the Silver++ CSV and sort by event_date.\n",
    "2. Add base features (fight duration, per‑round durations, winner encoding).\n",
    "3. Compute strike breakdowns and quality metrics.\n",
    "4. Convert to long format with two rows per fight (one per fighter).\n",
    "5. Compute rolling outcomes and rolling averages/ratios using NumPy.\n",
    "6. Pivot rolling stats back to wide format and merge onto the base data.\n",
    "7. Add ordinal fight numbers, ages and cumulative fight counts.\n",
    "8. Compute head‑to‑head differences and interactions between fighters.\n",
    "9. Coerce boolean columns and sanitise types, then write to CSV.\n",
    "\n",
    "Note: This version does not interact with BigQuery and can be run\n",
    "directly on Kaggle.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "# Suppress noisy pandas warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Rolling window sizes (3 to 15 previous fights)\n",
    "ROLLING_WINDOWS: list[int] = list(range(3, 16))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Utility functions\n",
    "# -----------------------------------------------------------------------------\n",
    "def _infer_per_round_categories(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Infer the set of per‑round strike categories present in the DataFrame.\n",
    "\n",
    "    Categories are derived from column names matching the pattern\n",
    "    'f_[12]_r[1-5]_<category>_(succ|att)'.  If no such columns are found,\n",
    "    a default set of common categories is returned.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    cats = set()\n",
    "    for c in df.columns:\n",
    "        m = re.match(r\"^f_[12]_r[1-5]_([A-Za-z0-9_]+)_(succ|att)$\", str(c))\n",
    "        if m:\n",
    "            cats.add(m.group(1))\n",
    "    if cats:\n",
    "        return sorted(cats)\n",
    "    return ['sig_strikes', 'total_strikes', 'takedown', 'head', 'body', 'leg']\n",
    "\n",
    "\n",
    "def time_to_minutes(t: str | None) -> float:\n",
    "    \"\"\"Convert a time string \"M:S\" to minutes, returning zero on failure.\"\"\"\n",
    "    try:\n",
    "        if not t:\n",
    "            return 0.0\n",
    "        m, s = t.split(\":\")\n",
    "        return (int(m) * 60 + int(s)) / 60.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def time_to_seconds(t: str | None) -> int:\n",
    "    \"\"\"Convert a time string \"M:S\" to seconds, returning zero on failure.\"\"\"\n",
    "    try:\n",
    "        if not t:\n",
    "            return 0\n",
    "        m, s = t.split(\":\")\n",
    "        return int(m) * 60 + int(s)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def _to_float(s: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Convert a Series to a float NumPy array, coercing non‑numeric to NaN.\"\"\"\n",
    "    return pd.to_numeric(s, errors='coerce').astype(float).to_numpy()\n",
    "\n",
    "\n",
    "def _safe_div(num: pd.Series | np.ndarray, den: pd.Series | np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform elementwise division safely, returning NaN where the denominator is <= 0.\n",
    "\n",
    "    Accepts pandas Series or NumPy arrays and coerces them to float arrays.  Zero\n",
    "    or negative denominators yield NaN.  This mirrors ``np.divide`` with a mask\n",
    "    but avoids issues with pandas nullable dtypes.\n",
    "    \"\"\"\n",
    "    n = _to_float(num)\n",
    "    d = _to_float(den)\n",
    "    out = np.full_like(n, np.nan, dtype=float)\n",
    "    mask = d > 0\n",
    "    out[mask] = n[mask] / d[mask]\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data retrieval and base feature preparation\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_full_fight_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the full fight data from the Kaggle input CSV.  The results are\n",
    "    ordered by ``event_date`` to ensure rolling computations are chronological.\n",
    "    \"\"\"\n",
    "    path = \"/kaggle/input/ufc-fight-forecast-complete-gold-modeling-dataset/UFC_full_data_silver.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values('event_date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_winner_encoded(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column ``winner_encoded`` encoding the result of the fight:\n",
    "        1 if the first fighter won, 0 if the second fighter won, -1 for draw/NC.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['winner_encoded'] = np.select(\n",
    "        [df['winner'] == df['f_1_name'],\n",
    "         df['winner'] == df['f_2_name'],\n",
    "         df['winner'].isin(['Draw', 'No Contest'])],\n",
    "        [1, 0, -1], default=-1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_base_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Derive base level features from raw fight data.\n",
    "\n",
    "    * Parse ``event_date`` strings into pandas Timestamps.\n",
    "    * Compute the total fight duration in minutes from ``finish_round`` and\n",
    "      ``finish_time``.\n",
    "    * Create per‑round duration columns ``r1_duration``..``r5_duration``.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "    # Fight duration in minutes\n",
    "    df['fight_duration_minutes'] = df.apply(\n",
    "        lambda r: (int(r['finish_round']) - 1) * 5 + time_to_minutes(r['finish_time']),\n",
    "        axis=1\n",
    "    )\n",
    "    # Per‑round durations\n",
    "    def _durations(row: pd.Series) -> pd.Series:\n",
    "        fin_r = int(row['finish_round']) if pd.notna(row['finish_round']) else 1\n",
    "        fin_m = time_to_minutes(row['finish_time'])\n",
    "        res: Dict[str, float] = {}\n",
    "        for r in range(1, 6):\n",
    "            if r < fin_r:\n",
    "                res[f'r{r}_duration'] = 5.0\n",
    "            elif r == fin_r:\n",
    "                res[f'r{r}_duration'] = fin_m\n",
    "            else:\n",
    "                res[f'r{r}_duration'] = 0.0\n",
    "        return pd.Series(res)\n",
    "    df = pd.concat([df, df.apply(_durations, axis=1)], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Strike breakdown calculations\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_strike_breakdowns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate strike accuracy and share metrics by body part and position.\n",
    "\n",
    "    For each fighter prefix (``f_1`` and ``f_2``) aggregate per‑round strike\n",
    "    statistics into fight‑level totals and compute accuracy and share metrics.\n",
    "    Also compute per‑round accuracy and shares.  Missing per‑round columns\n",
    "    are created on the fly and filled with zeros.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    categories = _infer_per_round_categories(df)\n",
    "    default_categories = ['head', 'body', 'leg', 'distance', 'clinch', 'ground']\n",
    "    categories_set = list(dict.fromkeys(default_categories + categories))\n",
    "    # Ensure expected per‑round columns exist\n",
    "    potential_cols = [\n",
    "        f\"{prefix}_r{r}_{cat}{suf}\"\n",
    "        for prefix in ['f_1', 'f_2']\n",
    "        for r in range(1, 6)\n",
    "        for cat in categories_set\n",
    "        for suf in ['_succ', '_att']\n",
    "    ]\n",
    "    missing = [c for c in potential_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df[missing] = 0\n",
    "    new_cols: Dict[str, pd.Series] = {}\n",
    "    for prefix in ['f_1', 'f_2']:\n",
    "        for cat in categories_set:\n",
    "            succ_cols = [f'{prefix}_r{r}_{cat}_succ' for r in range(1, 6)]\n",
    "            att_cols  = [f'{prefix}_r{r}_{cat}_att'  for r in range(1, 6)]\n",
    "            succ_total = df[succ_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "            att_total  = df[att_cols ].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1)\n",
    "            new_cols[f'{prefix}_{cat}_succ_total'] = succ_total\n",
    "            new_cols[f'{prefix}_{cat}_att_total']  = att_total\n",
    "            new_cols[f'{prefix}_{cat}_acc']        = _safe_div(succ_total, att_total)\n",
    "        hbl_cats = [c for c in ['head', 'body', 'leg'] if c in categories_set]\n",
    "        total_succ_hbl = sum(new_cols[f'{prefix}_{cat}_succ_total'] for cat in hbl_cats) if hbl_cats else 0\n",
    "        for cat in hbl_cats:\n",
    "            new_cols[f'{prefix}_{cat}_share'] = _safe_div(new_cols[f'{prefix}_{cat}_succ_total'], total_succ_hbl)\n",
    "        pos_cats = [c for c in ['distance', 'clinch', 'ground'] if c in categories_set]\n",
    "        total_succ_pos = sum(new_cols[f'{prefix}_{cat}_succ_total'] for cat in pos_cats) if pos_cats else 0\n",
    "        for cat in pos_cats:\n",
    "            new_cols[f'{prefix}_{cat}_share'] = _safe_div(new_cols[f'{prefix}_{cat}_succ_total'], total_succ_pos)\n",
    "        for r in range(1, 6):\n",
    "            total_round_hbl = sum(\n",
    "                pd.to_numeric(df[f'{prefix}_r{r}_{cat}_succ'], errors='coerce').fillna(0)\n",
    "                for cat in hbl_cats\n",
    "            ) if hbl_cats else 0\n",
    "            for cat2 in hbl_cats:\n",
    "                new_cols[f'{prefix}_r{r}_{cat2}_acc'] = _safe_div(\n",
    "                    df[f'{prefix}_r{r}_{cat2}_succ'], df[f'{prefix}_r{r}_{cat2}_att']\n",
    "                )\n",
    "                new_cols[f'{prefix}_r{r}_{cat2}_share'] = _safe_div(\n",
    "                    df[f'{prefix}_r{r}_{cat2}_succ'], total_round_hbl\n",
    "                )\n",
    "            total_round_pos = sum(\n",
    "                pd.to_numeric(df[f'{prefix}_r{r}_{cat}_succ'], errors='coerce').fillna(0)\n",
    "                for cat in pos_cats\n",
    "            ) if pos_cats else 0\n",
    "            for cat2 in pos_cats:\n",
    "                new_cols[f'{prefix}_r{r}_{cat2}_acc'] = _safe_div(\n",
    "                    df[f'{prefix}_r{r}_{cat2}_succ'], df[f'{prefix}_r{r}_{cat2}_att']\n",
    "                )\n",
    "                new_cols[f'{prefix}_r{r}_{cat2}_share'] = _safe_div(\n",
    "                    df[f'{prefix}_r{r}_{cat2}_succ'], total_round_pos\n",
    "                )\n",
    "    df2 = pd.concat([df, pd.DataFrame(new_cols, index=df.index)], axis=1)\n",
    "    return df2\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Quality feature calculations\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_quality_features(row: pd.Series, prefix: str) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute eight custom quality metrics for a single fight and fighter.\n",
    "\n",
    "    These heuristic metrics combine fight statistics into scores for\n",
    "    physical strength, punching power, dynamism, speed, timing, footwork,\n",
    "    chin and cardio.  The calculations mirror those in the BigQuery\n",
    "    pipeline.  Missing values are treated as zeros where appropriate.\n",
    "    \"\"\"\n",
    "    opp = 'f_2' if prefix == 'f_1' else 'f_1'\n",
    "    def _get_val(col: str, default=0):\n",
    "        val = row.get(col, default)\n",
    "        if val is None or (isinstance(val, (float, int, np.number)) and pd.isna(val)):\n",
    "            return default\n",
    "        if pd.isna(val):\n",
    "            return default\n",
    "        return val\n",
    "    fight_min = max(_get_val('fight_duration_minutes', 0.0), 1e-9)\n",
    "    max_min   = float(_get_val('num_rounds', 3)) * 5.0\n",
    "    td_succ = _get_val(f'{prefix}_takedown_succ', 0)\n",
    "    td_att  = _get_val(f'{prefix}_takedown_att', 0)\n",
    "    td_acc  = (td_succ / td_att) if td_att > 0 else 0.0\n",
    "    opp_td_succ = _get_val(f'{opp}_takedown_succ', 0)\n",
    "    opp_td_att  = _get_val(f'{opp}_takedown_att', 0)\n",
    "    td_def = 1.0 - (opp_td_succ / opp_td_att) if opp_td_att > 0 else 1.0\n",
    "    ctrl_sec = _get_val(f'{prefix}_ctrl_time_sec', 0)\n",
    "    ctrl_ratio = ctrl_sec / fight_min\n",
    "    rev_self = _get_val(f'{prefix}_reversals', 0)\n",
    "    rev_opp  = _get_val(f'{opp}_reversals', 0)\n",
    "    total_rev = rev_self + rev_opp\n",
    "    rev_share = (rev_self / total_rev) if total_rev > 0 else 0.0\n",
    "    physical_strength = 0.4 * td_acc + 0.3 * td_def + 0.2 * ctrl_ratio + 0.1 * rev_share\n",
    "    kd     = _get_val(f'{prefix}_knockdowns', 0)\n",
    "    s_succ = _get_val(f'{prefix}_sig_strikes_succ', 0)\n",
    "    s_att  = _get_val(f'{prefix}_sig_strikes_att', 0)\n",
    "    fighter_name = row.get(f'{prefix}_name')\n",
    "    winner = row.get('winner')\n",
    "    result = (row.get('result') or '')\n",
    "    is_win = (winner == fighter_name)\n",
    "    ko_win = bool(is_win and (('KO' in result) or ('TKO' in result)))\n",
    "    fin_round = int(_get_val('finish_round', 0))\n",
    "    num_r     = int(_get_val('num_rounds', 3))\n",
    "    finish_bonus = ((num_r - fin_round + 1) / num_r) if (ko_win and num_r > 0) else 0.0\n",
    "    power_ratio = (kd / s_succ) if s_succ > 0 else 0.0\n",
    "    punching_power = 0.5 * power_ratio + 0.3 * (1.0 if ko_win else 0.0) + 0.2 * finish_bonus\n",
    "    remaining = max(max_min - fight_min, 0.0)\n",
    "    finish_factor = (remaining / max_min) if (result != 'Decision' and max_min > 0) else 0.0\n",
    "    actions = s_succ + td_succ + _get_val(f'{prefix}_submission_att', 0) + kd\n",
    "    actions_per_min = actions / fight_min\n",
    "    kd_per_min = kd / fight_min\n",
    "    dynamika = 0.5 * finish_factor + 0.3 * actions_per_min + 0.2 * kd_per_min\n",
    "    opp_succ = _get_val(f'{opp}_sig_strikes_succ', 0)\n",
    "    opp_att  = _get_val(f'{opp}_sig_strikes_att', 0)\n",
    "    slpm = s_succ / fight_min\n",
    "    diff_per_min = (s_succ - opp_succ) / fight_min\n",
    "    str_def = 1.0 - (opp_succ / opp_att) if opp_att > 0 else 1.0\n",
    "    speed = 0.6 * slpm + 0.2 * diff_per_min + 0.2 * str_def\n",
    "    strike_acc  = (s_succ / s_att) if s_att > 0 else 0.0\n",
    "    kd_eff      = (kd / s_succ) if s_succ > 0 else 0.0\n",
    "    timing = 0.7 * strike_acc + 0.2 * kd_eff + 0.1 * td_acc\n",
    "    sapm = opp_succ / fight_min\n",
    "    footwork = 0.5 * str_def + 0.3 * td_def + 0.2 * (1.0 - (sapm / 10.0))\n",
    "    opp_kd = _get_val(f'{opp}_knockdowns', 0)\n",
    "    lost_by_ko = (not is_win) and (('KO' in result) or ('TKO' in result))\n",
    "    chin = 0.0 if lost_by_ko else (opp_succ / (opp_kd + 1))\n",
    "    duration_ratio = (fight_min / max_min) if max_min > 0 else 0.0\n",
    "    cardio = 0.7 * slpm + 0.3 * duration_ratio\n",
    "    return {\n",
    "        'physical_strength': physical_strength,\n",
    "        'punching_power':    punching_power,\n",
    "        'dynamika':          dynamika,\n",
    "        'speed':             speed,\n",
    "        'timing':            timing,\n",
    "        'footwork':          footwork,\n",
    "        'chin':              chin,\n",
    "        'cardio':            cardio,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Long format transformation\n",
    "# -----------------------------------------------------------------------------\n",
    "def prepare_long_format(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reshape the fight level DataFrame into long format with two rows per fight.\n",
    "\n",
    "    Two rows per fight (roles f_1 and f_2) allow us to compute\n",
    "    fighter‑centric rolling statistics.  This implementation builds\n",
    "    the new DataFrame in a vectorised fashion to avoid fragmentation.\n",
    "    \"\"\"\n",
    "    rows: list[pd.DataFrame] = []\n",
    "    cats = ['head', 'body', 'leg', 'distance', 'clinch', 'ground']\n",
    "    for prefix, opp, role in [('f_1', 'f_2', 'f_1'), ('f_2', 'f_1', 'f_2')]:\n",
    "        data: Dict[str, pd.Series] = {}\n",
    "        data['event_date'] = df['event_date']\n",
    "        data['fight_url']  = df['fight_url']\n",
    "        data['fighter']    = df[f'{prefix}_url']\n",
    "        data['opponent']   = df[f'{opp}_url']\n",
    "        data['role']       = role\n",
    "        is_winner = (df['winner'] == df[f'{prefix}_name']).astype(int)\n",
    "        is_loss   = (df['winner'] == df[f'{opp}_name']).astype(int)\n",
    "        data['is_winner'] = is_winner\n",
    "        data['is_loss']   = is_loss\n",
    "        data['finish_win'] = np.where((is_winner == 1) & df['result'].str.contains('KO|TKO', na=False), 1, 0)\n",
    "        data['submission_win'] = np.where((is_winner == 1) & (df['result'] == 'Submission'), 1, 0)\n",
    "        data['finish_loss'] = np.where((is_loss == 1) & df['result'].str.contains('KO|TKO', na=False), 1, 0)\n",
    "        data['submission_loss'] = np.where((is_loss == 1) & (df['result'] == 'Submission'), 1, 0)\n",
    "        for stat in ['sig_strikes_succ', 'sig_strikes_att', 'takedown_succ',\n",
    "                     'takedown_att', 'submission_att', 'reversals']:\n",
    "            data[f'fighter_{stat}'] = df[f'{prefix}_{stat}']\n",
    "            data[f'opp_{stat}']     = df[f'{opp}_{stat}']\n",
    "        data['fighter_ctrl_time_sec'] = df[f'{prefix}_ctrl_time_sec']\n",
    "        data['opp_ctrl_time_sec']     = df[f'{opp}_ctrl_time_sec']\n",
    "        data['fight_duration_minutes'] = df['fight_duration_minutes']\n",
    "        for r in range(1, 6):\n",
    "            sfx = f'_r{r}'\n",
    "            data[f'fighter_sig_strikes_succ_r{r}'] = df[f'{prefix}{sfx}_sig_strikes_succ']\n",
    "            data[f'fighter_sig_strikes_att_r{r}']  = df[f'{prefix}{sfx}_sig_strikes_att']\n",
    "            data[f'opp_sig_strikes_succ_r{r}']     = df[f'{opp}{sfx}_sig_strikes_succ']\n",
    "            data[f'opp_sig_strikes_att_r{r}']      = df[f'{opp}{sfx}_sig_strikes_att']\n",
    "            data[f'fighter_takedown_succ_r{r}']    = df[f'{prefix}{sfx}_td_1_succ']\n",
    "            data[f'fighter_takedown_att_r{r}']     = df[f'{prefix}{sfx}_td_1_att']\n",
    "            data[f'opp_takedown_succ_r{r}']        = df[f'{opp}{sfx}_td_1_succ']\n",
    "            data[f'opp_takedown_att_r{r}']         = df[f'{opp}{sfx}_td_1_att']\n",
    "            data[f'fighter_submission_att_r{r}']   = df[f'{prefix}{sfx}_submission_att']\n",
    "            data[f'opp_submission_att_r{r}']       = df[f'{opp}{sfx}_submission_att']\n",
    "            data[f'fighter_reversals_r{r}']        = df[f'{prefix}{sfx}_reversals']\n",
    "            data[f'opp_reversals_r{r}']            = df[f'{opp}{sfx}_reversals']\n",
    "            data[f'fighter_ctrl_r{r}_sec']         = df[f'{prefix}{sfx}_ctrl'].apply(time_to_seconds)\n",
    "            data[f'opp_ctrl_r{r}_sec']             = df[f'{opp}{sfx}_ctrl'].apply(time_to_seconds)\n",
    "            data[f'fighter_knockdowns_r{r}']       = df[f'{prefix}{sfx}_knockdowns']\n",
    "            data[f'opp_knockdowns_r{r}']           = df[f'{opp}{sfx}_knockdowns']\n",
    "            data[f'duration_r{r}']                 = df[f'r{r}_duration']\n",
    "            data[f'duration_r{r}_sec']             = df[f'r{r}_duration'] * 60.0\n",
    "        data['fighter_knockdowns'] = df[f'{prefix}_knockdowns']\n",
    "        data['opp_knockdowns']     = df[f'{opp}_knockdowns']\n",
    "        for cat in cats:\n",
    "            data[f'{cat}_acc']   = df[f'{prefix}_{cat}_acc']\n",
    "            data[f'{cat}_share'] = df[f'{prefix}_{cat}_share']\n",
    "        for r in range(1, 6):\n",
    "            for cat2 in cats:\n",
    "                data[f'{cat2}_acc_r{r}']   = df[f'{prefix}_r{r}_{cat2}_acc']\n",
    "                data[f'{cat2}_share_r{r}'] = df[f'{prefix}_r{r}_{cat2}_share']\n",
    "        qual_df = df.apply(lambda row: compute_quality_features(row, prefix), axis=1, result_type='expand')\n",
    "        for col in ['physical_strength','punching_power','dynamika','speed','timing','footwork','chin','cardio']:\n",
    "            data[col] = qual_df[col]\n",
    "        t = pd.DataFrame(data)\n",
    "        rows.append(t)\n",
    "    long_df = pd.concat(rows, ignore_index=True)\n",
    "    return long_df.sort_values(['fighter', 'event_date']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Rolling outcomes\n",
    "# -----------------------------------------------------------------------------\n",
    "def calculate_outcomes(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute rolling win/loss counts and streaks for a single fighter.\n",
    "\n",
    "    Uses cumulative sums to obtain the sum of the previous ``n`` fights\n",
    "    efficiently.  Rolling windows exclude the current fight by subtracting\n",
    "    cumulative sums at index ``i-n`` from those at ``i`` (i.e., sum of\n",
    "    rows ``i-n`` through ``i-1``).  Streaks are capped by the window\n",
    "    length.\n",
    "    \"\"\"\n",
    "    g = group.sort_values('event_date').reset_index(drop=True)\n",
    "    n_rows = len(g)\n",
    "    is_win    = g['is_winner'].to_numpy(dtype=int)\n",
    "    finish_win= g['finish_win'].to_numpy(dtype=int)\n",
    "    sub_win   = g['submission_win'].to_numpy(dtype=int)\n",
    "    is_loss   = g['is_loss'].to_numpy(dtype=int)\n",
    "    finish_loss= g['finish_loss'].to_numpy(dtype=int)\n",
    "    sub_loss  = g['submission_loss'].to_numpy(dtype=int)\n",
    "    def cumsum_with_zero(x: np.ndarray) -> np.ndarray:\n",
    "        cs = np.empty(n_rows + 1, dtype=int)\n",
    "        cs[0] = 0\n",
    "        cs[1:] = x.cumsum()\n",
    "        return cs\n",
    "    cs_win   = cumsum_with_zero(is_win)\n",
    "    cs_fwin  = cumsum_with_zero(finish_win)\n",
    "    cs_swin  = cumsum_with_zero(sub_win)\n",
    "    cs_loss  = cumsum_with_zero(is_loss)\n",
    "    cs_floss = cumsum_with_zero(finish_loss)\n",
    "    cs_sloss = cumsum_with_zero(sub_loss)\n",
    "    # Precompute streaks up to previous row\n",
    "    streak_prev = np.zeros(n_rows, dtype=int)\n",
    "    losing_prev = np.zeros(n_rows, dtype=int)\n",
    "    run_win = 0\n",
    "    run_loss = 0\n",
    "    for i in range(n_rows):\n",
    "        if is_win[i] == 1:\n",
    "            run_win += 1\n",
    "        else:\n",
    "            run_win = 0\n",
    "        if is_loss[i] == 1:\n",
    "            run_loss += 1\n",
    "        else:\n",
    "            run_loss = 0\n",
    "        streak_prev[i] = run_win\n",
    "        losing_prev[i] = run_loss\n",
    "    out_data: Dict[str, np.ndarray] = {}\n",
    "    for n in ROLLING_WINDOWS:\n",
    "        idx = np.arange(n_rows)\n",
    "        prev_idx = np.maximum(0, idx - n)\n",
    "        wins_n   = cs_win[idx]   - cs_win[prev_idx]\n",
    "        fwin_n   = cs_fwin[idx]  - cs_fwin[prev_idx]\n",
    "        swin_n   = cs_swin[idx]  - cs_swin[prev_idx]\n",
    "        loss_n   = cs_loss[idx]  - cs_loss[prev_idx]\n",
    "        floss_n  = cs_floss[idx] - cs_floss[prev_idx]\n",
    "        sloss_n  = cs_sloss[idx] - cs_sloss[prev_idx]\n",
    "        streak_n = np.zeros(n_rows, dtype=int)\n",
    "        losing_n = np.zeros(n_rows, dtype=int)\n",
    "        if n_rows > 1:\n",
    "            streak_n[1:] = np.minimum(streak_prev[:-1], n)\n",
    "            losing_n[1:] = np.minimum(losing_prev[:-1], n)\n",
    "        out_data[f'wins_{n}']          = wins_n\n",
    "        out_data[f'finish_wins_{n}']   = fwin_n\n",
    "        out_data[f'sub_wins_{n}']      = swin_n\n",
    "        out_data[f'losses_{n}']        = loss_n\n",
    "        out_data[f'finish_losses_{n}'] = floss_n\n",
    "        out_data[f'sub_losses_{n}']    = sloss_n\n",
    "        out_data[f'streak_{n}']        = streak_n\n",
    "        out_data[f'losing_streak_{n}'] = losing_n\n",
    "    return pd.concat([g, pd.DataFrame(out_data, index=g.index)], axis=1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Rolling metrics (averages and ratios)\n",
    "# -----------------------------------------------------------------------------\n",
    "def calculate_group(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute rolling averages and ratios for a single fighter.\n",
    "\n",
    "    Rolling windows exclude the current fight by looking back over the\n",
    "    previous ``n`` fights.  Metrics include per‑fight and per‑round\n",
    "    statistics, accuracy and share breakdowns, and the eight quality\n",
    "    metrics.  All operations are vectorised via NumPy to avoid\n",
    "    performance bottlenecks.\n",
    "    \"\"\"\n",
    "    g = group.sort_values('event_date').reset_index(drop=True)\n",
    "    n_rows = len(g)\n",
    "    new_cols: Dict[str, np.ndarray] = {}\n",
    "    metrics: Dict[str, Tuple[str | None, str | None, bool, bool]] = {}\n",
    "    metrics.update({\n",
    "        'slpm':      ('fighter_sig_strikes_succ','fight_duration_minutes',False,False),\n",
    "        'str_acc':   ('fighter_sig_strikes_succ','fighter_sig_strikes_att',False,False),\n",
    "        'sapm':      ('opp_sig_strikes_succ','fight_duration_minutes',False,False),\n",
    "        'str_def':   ('opp_sig_strikes_succ','opp_sig_strikes_att',True,False),\n",
    "        'td_avg':    ('fighter_takedown_succ','fight_duration_minutes',False,False),\n",
    "        'td_acc':    ('fighter_takedown_succ','fighter_takedown_att',False,False),\n",
    "        'td_def':    ('opp_takedown_succ','opp_takedown_att',True,False),\n",
    "        'sub_avg':   ('fighter_submission_att','fight_duration_minutes',False,False),\n",
    "        'ctrl_ratio':('fighter_ctrl_time_sec','fight_duration_minutes',False,False),\n",
    "    })\n",
    "    for r in range(1, 6):\n",
    "        s = f'_r{r}'\n",
    "        metrics.update({\n",
    "            f'slpm{s}':      (f'fighter_sig_strikes_succ{s}', f'duration{s}', False, False),\n",
    "            f'str_acc{s}':   (f'fighter_sig_strikes_succ{s}', f'fighter_sig_strikes_att{s}', False, False),\n",
    "            f'sapm{s}':      (f'opp_sig_strikes_succ{s}',     f'duration{s}', False, False),\n",
    "            f'str_def{s}':   (f'opp_sig_strikes_succ{s}',     f'opp_sig_strikes_att{s}', True, False),\n",
    "            f'td_avg{s}':    (f'fighter_takedown_succ{s}',    f'duration{s}', False, False),\n",
    "            f'td_acc{s}':    (f'fighter_takedown_succ{s}',    f'fighter_takedown_att{s}', False, False),\n",
    "            f'td_def{s}':    (f'opp_takedown_succ{s}',        f'opp_takedown_att{s}', True, False),\n",
    "            f'sub_avg{s}':   (f'fighter_submission_att{s}',   f'duration{s}', False, False),\n",
    "            f'ctrl_ratio{s}':(f'fighter_ctrl{s}_sec',         f'duration{s}_sec', False, False),\n",
    "        })\n",
    "    cats = ['head','body','leg','distance','clinch','ground']\n",
    "    for cat in cats:\n",
    "        metrics[f'{cat}_acc']   = (f'{cat}_acc', None, False, True)\n",
    "        metrics[f'{cat}_share'] = (f'{cat}_share', None, False, True)\n",
    "        for r in range(1, 6):\n",
    "            metrics[f'{cat}_acc_r{r}']   = (f'{cat}_acc_r{r}', None, False, True)\n",
    "            metrics[f'{cat}_share_r{r}'] = (f'{cat}_share_r{r}', None, False, True)\n",
    "    for q in ['physical_strength','punching_power','dynamika','speed','timing','footwork','chin','cardio']:\n",
    "        metrics[q] = (q, None, False, True)\n",
    "    cumsum_cache: Dict[str, np.ndarray] = {}\n",
    "    count_cache: Dict[str, np.ndarray] = {}\n",
    "    for name, (num, den, invert, is_avg) in metrics.items():\n",
    "        if is_avg:\n",
    "            if num not in cumsum_cache:\n",
    "                arr = pd.to_numeric(g[num], errors='coerce').to_numpy(dtype=float)\n",
    "                csum = np.empty(n_rows + 1, dtype=float)\n",
    "                csum[0] = 0.0\n",
    "                csum[1:] = np.nan_to_num(arr, nan=0.0).cumsum()\n",
    "                cumsum_cache[num] = csum\n",
    "                cnt = np.empty(n_rows + 1, dtype=int)\n",
    "                cnt[0] = 0\n",
    "                cnt[1:] = (~np.isnan(arr)).cumsum()\n",
    "                count_cache[num] = cnt\n",
    "        else:\n",
    "            for col in [num, den]:\n",
    "                if col not in cumsum_cache:\n",
    "                    arr = pd.to_numeric(g[col], errors='coerce').to_numpy(dtype=float)\n",
    "                    csum = np.empty(n_rows + 1, dtype=float)\n",
    "                    csum[0] = 0.0\n",
    "                    csum[1:] = np.nan_to_num(arr, nan=0.0).cumsum()\n",
    "                    cumsum_cache[col] = csum\n",
    "    for n in ROLLING_WINDOWS:\n",
    "        idx = np.arange(n_rows)\n",
    "        prev_idx = np.maximum(0, idx - n)\n",
    "        for name, (num, den, invert, is_avg) in metrics.items():\n",
    "            out_name = f'{name}_{n}'\n",
    "            if is_avg:\n",
    "                csum = cumsum_cache[num]\n",
    "                cnt  = count_cache[num]\n",
    "                sums = csum[idx] - csum[prev_idx]\n",
    "                counts = cnt[idx] - cnt[prev_idx]\n",
    "                vals = np.divide(sums, counts, out=np.full(n_rows, np.nan, dtype=float), where=counts > 0)\n",
    "            else:\n",
    "                num_csum = cumsum_cache[num]\n",
    "                den_csum = cumsum_cache[den]\n",
    "                num_sum = num_csum[idx] - num_csum[prev_idx]\n",
    "                den_sum = den_csum[idx] - den_csum[prev_idx]\n",
    "                vals = np.divide(num_sum, den_sum, out=np.full(n_rows, np.nan, dtype=float), where=den_sum > 0)\n",
    "                if invert:\n",
    "                    vals = 1.0 - vals\n",
    "            new_cols[out_name] = vals\n",
    "    return pd.concat([g, pd.DataFrame(new_cols, index=g.index)], axis=1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Merging and additional feature engineering\n",
    "# -----------------------------------------------------------------------------\n",
    "def merge_rolling_and_outcomes(df: pd.DataFrame, long_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge rolling statistics back onto the fight level DataFrame.  Rolling\n",
    "    columns are pivoted by fighter role (f_1/f_2) and flattened.  Missing\n",
    "    rolling values are filled with zeros.\n",
    "    \"\"\"\n",
    "    before_cols = set(df.columns)\n",
    "    roll_cols = [c for c in long_df.columns if any(c.endswith(f'_{n}') for n in ROLLING_WINDOWS)]\n",
    "    if not roll_cols:\n",
    "        return df\n",
    "    pivot = long_df.pivot(index='fight_url', columns='role', values=roll_cols)\n",
    "    pivot.columns = [f'{col}_{role}' for col, role in pivot.columns]\n",
    "    merged = df.merge(pivot, on='fight_url', how='left')\n",
    "    added_cols = [c for c in merged.columns if c not in before_cols]\n",
    "    if added_cols:\n",
    "        merged[added_cols] = merged[added_cols].fillna(0)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def add_fight_ordinal(df: pd.DataFrame, long_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = long_df.copy()\n",
    "    tmp['fight_ordinal'] = tmp.groupby('fighter').cumcount() + 1\n",
    "    pv = tmp.pivot(index='fight_url', columns='role', values='fight_ordinal')\n",
    "    pv.columns = [f'fight_ordinal_{c}' for c in pv.columns]\n",
    "    return df.merge(pv, on='fight_url', how='left')\n",
    "\n",
    "\n",
    "def add_additional_features(df: pd.DataFrame, long_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out['fighter_dob_f_1'] = pd.to_datetime(out['f_1_fighter_dob'], errors='coerce')\n",
    "    out['fighter_dob_f_2'] = pd.to_datetime(out['f_2_fighter_dob'], errors='coerce')\n",
    "    out['f_1_age'] = ((out['event_date'] - out['fighter_dob_f_1']).dt.days // 365)\n",
    "    out['f_2_age'] = ((out['event_date'] - out['fighter_dob_f_2']).dt.days // 365)\n",
    "    tmp = long_df.copy()\n",
    "    tmp['fight_count'] = tmp.groupby('fighter').cumcount()\n",
    "    pv = tmp.pivot(index='fight_url', columns='role', values='fight_count')\n",
    "    pv.columns = [f'{c}_fight_number' for c in pv.columns]\n",
    "    out = out.merge(pv, on='fight_url', how='left')\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_diff_and_interaction_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    diff_cols: Dict[str, np.ndarray] = {}\n",
    "    diff_cols['diff_age'] = (out['f_1_age'].to_numpy(dtype=float) - out['f_2_age'].to_numpy(dtype=float))\n",
    "    diff_cols['diff_fight_number'] = (\n",
    "        out['fight_ordinal_f_1'].to_numpy(dtype=float) - out['fight_ordinal_f_2'].to_numpy(dtype=float)\n",
    "    )\n",
    "    f1_rank = out.get('f_1_ranking').to_numpy(dtype=float) if 'f_1_ranking' in out else np.full(len(out), np.nan)\n",
    "    f2_rank = out.get('f_2_ranking').to_numpy(dtype=float) if 'f_2_ranking' in out else np.full(len(out), np.nan)\n",
    "    diff_cols['diff_ranking'] = f1_rank - f2_rank\n",
    "    f1_odds = out.get('f_1_odds').to_numpy(dtype=float) if 'f_1_odds' in out else np.full(len(out), np.nan)\n",
    "    f2_odds = out.get('f_2_odds').to_numpy(dtype=float) if 'f_2_odds' in out else np.full(len(out), np.nan)\n",
    "    diff_cols['diff_odds'] = f1_odds - f2_odds\n",
    "    base_metrics = [\n",
    "        'slpm','str_acc','sapm','str_def','td_avg','td_acc','td_def','sub_avg','ctrl_ratio',\n",
    "        'physical_strength','punching_power','dynamika','speed','timing','footwork','chin','cardio'\n",
    "    ]\n",
    "    windows = list(ROLLING_WINDOWS)\n",
    "    for m in base_metrics:\n",
    "        for n in windows:\n",
    "            c1 = f'{m}_{n}_f_1'\n",
    "            c2 = f'{m}_{n}_f_2'\n",
    "            if c1 in out.columns and c2 in out.columns:\n",
    "                diff_cols[f'diff_{m}_{n}'] = (\n",
    "                    out[c1].to_numpy(dtype=float) - out[c2].to_numpy(dtype=float)\n",
    "                )\n",
    "    cats = ['head','body','leg','distance','clinch','ground']\n",
    "    suffixes = ['', '_r1','_r2','_r3','_r4','_r5']\n",
    "    types = ['acc','share']\n",
    "    for base in cats:\n",
    "        for suf in suffixes:\n",
    "            for t in types:\n",
    "                name = f'{base}_{t}{suf}'\n",
    "                for n in windows:\n",
    "                    c1 = f'{name}_{n}_f_1'\n",
    "                    c2 = f'{name}_{n}_f_2'\n",
    "                    if c1 in out.columns and c2 in out.columns:\n",
    "                        diff_cols[f'diff_{name}_{n}'] = (\n",
    "                            out[c1].to_numpy(dtype=float) - out[c2].to_numpy(dtype=float)\n",
    "                        )\n",
    "    if diff_cols:\n",
    "        diff_df = pd.DataFrame(diff_cols, index=out.index)\n",
    "        out = pd.concat([out, diff_df], axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Boolean and dtype sanitisation\n",
    "# -----------------------------------------------------------------------------\n",
    "def _coerce_boolean_like(df: pd.DataFrame) -> list[str]:\n",
    "    touched: list[str] = []\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        if s.dtype == bool:\n",
    "            df[c] = s.astype('boolean')\n",
    "            touched.append(c)\n",
    "            continue\n",
    "        if s.dtype == object:\n",
    "            non_na = s.dropna()\n",
    "            if len(non_na) and non_na.isin([True, False]).all():\n",
    "                df[c] = s.astype('boolean')\n",
    "                touched.append(c)\n",
    "    return touched\n",
    "\n",
    "\n",
    "def _coerce_booleans_for_csv(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Convert boolean and boolean‑like columns to native Python bool for CSV output.\n",
    "    Missing values are filled with False.  Integer 0/1 columns are left unchanged.\n",
    "    \"\"\"\n",
    "    touched: list[str] = []\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        try:\n",
    "            if pd.api.types.is_bool_dtype(s):\n",
    "                df[c] = s.fillna(False).astype(bool)\n",
    "                touched.append(c)\n",
    "                continue\n",
    "            if s.dtype == object:\n",
    "                unique_vals = set(s.dropna().unique().tolist())\n",
    "                if unique_vals.issubset({True, False, 1, 0, '1','0','true','false','True','False','TRUE','FALSE'}):\n",
    "                    df[c] = (\n",
    "                        s.map(lambda x: True if x in {True,1,'1','true','True','TRUE'} else False)\n",
    "                          .fillna(False)\n",
    "                          .astype(bool)\n",
    "                    )\n",
    "                    touched.append(c)\n",
    "                    continue\n",
    "        except Exception:\n",
    "            df[c] = s.fillna(0).map(lambda x: 1 if x in {True,1,'1','true','True','TRUE'} else 0).astype('int8')\n",
    "            touched.append(c)\n",
    "    return touched\n",
    "\n",
    "\n",
    "def _sanitize_all_dtypes_for_csv(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
    "    if len(num_cols):\n",
    "        out[num_cols] = out[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    _coerce_booleans_for_csv(out)\n",
    "    cat_cols = out.select_dtypes(include=['category']).columns\n",
    "    if len(cat_cols):\n",
    "        out[cat_cols] = out[cat_cols].astype('string')\n",
    "    obj_cols = [c for c in out.columns if out[c].dtype == object]\n",
    "    for c in obj_cols:\n",
    "        if out[c].dropna().map(lambda v: isinstance(v, (list, dict, set, tuple))).any():\n",
    "            out[c] = out[c].apply(lambda v: None if pd.isna(v) else str(v))\n",
    "    bool_cols = [c for c in out.columns if pd.api.types.is_bool_dtype(out[c])]\n",
    "    for c in bool_cols:\n",
    "        out[c] = out[c].fillna(False).astype(bool)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------------------------------------------------------\n",
    "def process_new_fights() -> None:\n",
    "    \"\"\"Run the full processing pipeline and write the result to CSV.\"\"\"\n",
    "    total_start = time.time()\n",
    "    df = get_full_fight_data()\n",
    "    df = add_winner_encoded(df)\n",
    "    df = prepare_base_features(df)\n",
    "    df = compute_strike_breakdowns(df)\n",
    "    long_df = prepare_long_format(df)\n",
    "    # Rolling outcomes and metrics\n",
    "    long_df = long_df.groupby('fighter', group_keys=False).apply(calculate_outcomes)\n",
    "    long_df = long_df.groupby('fighter', group_keys=False).apply(calculate_group)\n",
    "    # Merge rolling stats back\n",
    "    before_cols = set(df.columns)\n",
    "    df = merge_rolling_and_outcomes(df, long_df)\n",
    "    added_cols = [c for c in df.columns if c not in before_cols]\n",
    "    df = add_fight_ordinal(df, long_df)\n",
    "    df = add_additional_features(df, long_df)\n",
    "    df = add_diff_and_interaction_features(df)\n",
    "    # Fill missing rolling columns with zero\n",
    "    if added_cols:\n",
    "        df[added_cols] = df[added_cols].fillna(0)\n",
    "    rolling_like = [c for c in df.columns if any(c.endswith(f'_{n}') for n in ROLLING_WINDOWS)]\n",
    "    if rolling_like:\n",
    "        df[rolling_like] = df[rolling_like].fillna(0)\n",
    "    _coerce_boolean_like(df)\n",
    "    df = _sanitize_all_dtypes_for_csv(df)\n",
    "    # Write to CSV in Kaggle working directory\n",
    "    output_path = 'ufc_model_full_analysis_rounds.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    elapsed = time.time() - total_start\n",
    "    print(f\"✅ Written {output_path} — {len(df)} records | {elapsed:.2f}s\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_new_fights()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8007030,
     "sourceId": 13218530,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 289.357089,
   "end_time": "2025-09-30T22:32:09.835699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T22:27:20.478610",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
